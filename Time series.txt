# =========================
# 1. IMPORTS
# =========================
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
warnings.filterwarnings("ignore")

device = "cuda" if torch.cuda.is_available() else "cpu"

# =========================
# 2. DATA GENERATION
# =========================
np.random.seed(42)

days = 3 * 365
t = np.arange(days)

data = pd.DataFrame({
    "feature_1": np.sin(2 * np.pi * t / 30) + np.random.normal(0, 0.1, days),
    "feature_2": np.cos(2 * np.pi * t / 90) + np.random.normal(0, 0.1, days),
    "feature_3": t * 0.0005 + np.random.normal(0, 0.05, days),
    "feature_4": np.random.normal(0, 1, days),
    "target": np.sin(2 * np.pi * t / 7) + 0.3 * np.cos(2 * np.pi * t / 365)
})

scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# =========================
# 3. DATASET CLASS
# =========================
class TimeSeriesDataset(Dataset):
    def __init__(self, data, seq_len=30):
        self.X, self.y = [], []
        for i in range(len(data) - seq_len):
            self.X.append(data[i:i+seq_len, :-1])
            self.y.append(data[i+seq_len, -1])

        self.X = torch.tensor(self.X, dtype=torch.float32)
        self.y = torch.tensor(self.y, dtype=torch.float32)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

# =========================
# 4. TRANSFORMER MODEL
# =========================
class TransformerModel(nn.Module):
    def __init__(self, features, seq_len=30, d_model=64, nhead=4):
        super().__init__()

        self.embedding = nn.Linear(features, d_model)
        self.pos_encoder = nn.Parameter(torch.randn(1, seq_len, d_model))

        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            batch_first=True
        )

        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=2)
        self.fc = nn.Linear(d_model, 1)

    def forward(self, x):
        x = self.embedding(x) + self.pos_encoder
        x = self.transformer(x)
        return self.fc(x[:, -1, :])

# =========================
# 5. LSTM BASELINE
# =========================
class LSTMModel(nn.Module):
    def __init__(self, features):
        super().__init__()

        self.lstm = nn.LSTM(features, 64, batch_first=True)
        self.fc = nn.Linear(64, 1)

    def forward(self, x):
        _, (h, _) = self.lstm(x)
        return self.fc(h[-1])

# =========================
# 6. TRAIN FUNCTION
# =========================
def train_model(model, loader, epochs=15):
    model.train()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    loss_fn = nn.MSELoss()

    for _ in range(epochs):
        for X, y in loader:
            X, y = X.to(device), y.to(device)

            optimizer.zero_grad()
            loss = loss_fn(model(X).squeeze(), y)
            loss.backward()
            optimizer.step()

# =========================
# 7. ROLLING ORIGIN CV
# =========================
def rolling_cv(model_class):
    rmses, maes = [], []

    for split in range(500, 900, 100):
        train_data = data_scaled[:split]
        test_data = data_scaled[split:split+100]

        train_ds = TimeSeriesDataset(train_data)
        test_ds = TimeSeriesDataset(test_data)

        train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)
        test_dl = DataLoader(test_ds, batch_size=32)

        model = model_class(train_data.shape[1] - 1).to(device)
        train_model(model, train_dl)

        model.eval()
        preds, actuals = [], []

        with torch.no_grad():
            for X, y in test_dl:
                pred = model(X.to(device)).cpu().numpy()
                preds.extend(pred.flatten())
                actuals.extend(y.numpy())

        rmses.append(mean_squared_error(actuals, preds, squared=False))
        maes.append(mean_absolute_error(actuals, preds))

    return np.mean(rmses), np.mean(maes)

# =========================
# 8. EVALUATION
# =========================
tr_rmse, tr_mae = rolling_cv(TransformerModel)
lstm_rmse, lstm_mae = rolling_cv(LSTMModel)

print("Transformer RMSE:", tr_rmse)
print("Transformer MAE :", tr_mae)
print("LSTM RMSE       :", lstm_rmse)
print("LSTM MAE        :", lstm_mae)